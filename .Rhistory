View(sample)
sample[, c(1, 5, 2)]
#| echo: false
#| results: asis
kable(sample[c(1, 5, 2), ])
View(sample)
#| echo: false
#| results: asis
filtered_sample <- sample[c(1, 5, 2), ]
View(filtered_sample)
View(sample)
sample <- comments %>%
filter(index %in% c(5, 202, 100, 141, 179)) %>%
mutate(index = c(1:5))
View(sample)
sample <- comments %>%
filter(index %in% c(5, 100, 141, 179, 202)) %>%
slice(c(1, 4, 5, 2, 3)) %>%
mutate(index = c(1:5))
View(sample)
sample <- comments %>%
filter(index %in% c(5, 100, 141, 179, 202)) %>%
slice(c(1, 4, 2, 3, 5)) %>%
mutate(index = c(1:5))
View(comments)
View(sample)
sample <- comments %>%
filter(index %in% c(5, 100, 141, 179, 202)) %>%
slice(c(1, 4, 3, 2, 5)) %>%
mutate(index = c(1:5)) %>%
rename(Index = index,
Comments = OpenEndedComments)
View(sample)
# Save sample data
write.csv(sample, file = "sample data.csv", row.names = F)
sample <- comments %>%
filter(index %in% c(5, 100, 141, 179, 202)) %>%
slice(c(1, 4, 3, 2, 5)) %>%
mutate(index = c(1:5)) %>%
rename(Index = index,
Comments = OpenEndedComments)
# Save sample data
write.csv(sample, file = "sample data.csv", row.names = F)
sample <- comments %>%
filter(index %in% c(5, 100, 141, 179, 202)) %>%
slice(c(1, 4, 3, 2, 5)) %>%
mutate(index = c(1:5)) %>%
rename(comments = OpenEndedComments)
View(sample)
# Save sample data
write.csv(sample, file = "sample data.csv", row.names = F)
library(spacyr)
spacy_initialize(model = "en_core_web_lg")
mask_entities <- function(text) {
parsed <- spacy_parse(text, entity = TRUE)
persons <- parsed %>% filter(str_detect(entity, "PERSON")) %>% select(token)
if (nrow(persons) > 0) {
masked <- str_replace_all(text, regex(paste0("\\b(", paste(persons$token, collapse="|"), ")\\b")), "[PERSON]")
} else {
masked <- text
}
return(masked)
}
sample_name_masked$comments[i] <- mask_entities(sample_name_masked$comments[i])
# Mask names
sample_name_masked <- sample
for (i in 1:nrow(sample_name_masked)) {
sample_name_masked$comments[i] <- mask_entities(sample_name_masked$comments[i])
}
View(sample_name_masked)
save(sample, sample_name_masked, file = "data.RData")
load('/Users/xia2128737/Library/CloudStorage/GoogleDrive-xia2128737@paradisevalley.edu/Shared drives/PV IE Team/Conferences/2025 Student Success Conference/r project/data.RData')
load('/Users/xia2128737/Library/CloudStorage/GoogleDrive-xia2128737@paradisevalley.edu/Shared drives/PV IE Team/Conferences/2025 Student Success Conference/r project/data.RData')
write.csv(sample_name_masked, file = "sample data name masked.csv", row.names = F)
library(httr)
library(jsonlite)
library(tidyverse)
library(spacyr)
# To save your OpenAI API key in the .Renviron file, you can run this in the console:
# file.edit("~/.Renviron")
# Then write this in the .Renviron file:
# OPENAI_API_KEY = XXX
# Import API key that you saved in the .Renviron file
api_key <- Sys.getenv("OPENAI_API_KEY")
# Read data
comments <- read.csv("sample data.csv") # Change it to your file path
# Function to mask names mentioned in the data
spacy_initialize(model = "en_core_web_lg")
mask_entities <- function(text) {
parsed <- spacy_parse(text, entity = TRUE)
persons <- parsed %>% filter(str_detect(entity, "PERSON")) %>% select(token)
if (nrow(persons) > 0) {
masked <- str_replace_all(text, regex(paste0("\\b(", paste(persons$token, collapse="|"), ")\\b")), "[PERSON]")
} else {
masked <- text
}
return(masked)
}
# Mask names
for (i in 1:nrow(comments)) {
comments$OpenEndedComments[i] <- mask_entities(comments$OpenEndedComments[i])
}
View(comments)
View(comments)
View(comments)
# Get data
rnl <- read_excel("/Users/xia2128737/Library/CloudStorage/GoogleDrive-xia2128737@paradisevalley.edu/Shared drives/PV IE Team/Surveys/Ruffalo Noel Levitz Survey 2025/data/data 2025.xlsx")
library(tidyverse)
library(readxl)
library(spacyr)
# Get data
rnl <- read_excel("/Users/xia2128737/Library/CloudStorage/GoogleDrive-xia2128737@paradisevalley.edu/Shared drives/PV IE Team/Surveys/Ruffalo Noel Levitz Survey 2025/data/data 2025.xlsx")
rnl <- rnl %>% filter(!if_all(everything(), is.na))
rnl25 <- rnl %>% filter(SurveyAdministrationName == "Paradise Valley Community College - SSI - 4/2025")
comments <- rnl25 %>% mutate(index = c(1:nrow(rnl25))) %>%
select(index, OpenEndedComments) %>%
filter(!is.na(OpenEndedComments))
sample <- comments %>%
filter(index %in% c(5, 100, 141, 179, 202)) %>%
slice(c(1, 4, 3, 2, 5)) %>%
mutate(index = c(1:5)) %>%
rename(comment = OpenEndedComments)
# Save sample data
write.csv(sample, file = "sample data.csv", row.names = F)
# Read data
comments <- read.csv("sample data.csv") # Change it to your file path
View(comments)
# Mask names
for (i in 1:nrow(comments)) {
comments$comment[i] <- mask_entities(comments$comment[i])
}
View(comments)
# Convert the dataframe to text
comments_text <- paste(capture.output(write.csv(comments, row.names = F)), collapse = "\n")
# Prompt
prompt <- paste("You are analyzing open-ended comments from a student satisfaction survey.\n\n", comments_text,
"\n\n Task 1: Determine the overall perception of each comment toward the college.
Choose one of the following categories: (a) positive, (b) negative, (c) neutral, or (d) mixed.
Task 2: Identify the topics mentioned in each comment.
Use clear and descriptive labels such as advising, class availability, faculty, etc.
Please create new topic labels as needed.
List all relevant labels, separated by commas, such as ‘advising, class availability’.
Return the results in a table with the following three columns: index, perception, and labels.")
# API call
response <- POST(
url = "https://api.openai.com/v1/chat/completions",
add_headers(
Authorization = paste("Bearer", api_key),
"Content-Type" = "application/json"
),
body = toJSON(list(
model = "gpt-4o",
messages = list(
list(role = "user", content = prompt)
)
), auto_unbox = TRUE)
)
content <- content(response, "parsed")
cat(content$choices[[1]]$message$content)
# Save the table
text <- content$choices[[1]]$message$content
lines <- unlist(strsplit(text, "\n"))
table_lines <- lines[grepl("^\\|", lines)]
# Remove the first two rows
data_lines <- table_lines[-c(1, 2)]
data_lines
# Convert to a matrix
max_cols <- max(sapply(str_split(data_lines, "\\|"), length))
data_matrix <- str_split_fixed(data_lines, "\\|", max_cols)
# Convert to a dataframe
data_df <- as.data.frame(data_matrix)
View(data_df)
# Clean the dataframe
data_df <- data_df[, c(2:4)]
data_df <- data_df %>% mutate(across(everything(), str_trim))
names(data_df) <- c("index", "perception", "labels")
data_df$index <- as.numeric(data_df$index)
# Join the results back to the comments data
comments_ai <- comments %>% left_join(data_df, by = "index")
View(comments_ai)
# Save results
write.csv(comments_ai, file = "ai_output.csv", row.names = F)
# Load AI output
ai_output <- read.csv("ai_output.csv")
View(ai_output)
save(sample, sample_name_masked, ai_output, file = "data.RData")
View(comments)
prompt <- paste("You are analyzing open-ended comments from a student satisfaction survey.\n\n", comments_text,
"\n\n Your task is to code each comment using none, one, or more of the following standardized labels:
Campus Climate – Comments about the general environment or sense of belonging on campus (e.g., feeling cared for, welcomed, respected, or included).
Advising – Comments about academic advising, advisor helpfulness, or access to advisors.
Classes/Schedules – Comments about class offerings, availability, scheduling, or course registration timing.
Faculty/Instruction – Comments about instructors, teaching quality, or classroom experiences.
Facilities – Comments about physical campus resources such as parking lots, gyms, cafeterias, buildings, or classrooms.
Academic Program – Comments about specific academic programs or majors (e.g., Nursing, Music, Education).
Admissions/Registration – Comments about enrollment, admissions, or registration processes.
Other Services – Comments about campus services other than Advising or Admissions/Registration, such as Veterans Services, Counseling, Athletics, Library, Tutoring, Career Services, Disability Services, or Student Clubs.
Instructions: Please do not create new labels. If a comment fits multiple labels, include all relevant ones separated by commas, such as ‘Campus Climate, Academic Program’.
The output should be a table with two columns: index and labels.")
# API call
response <- POST(
url = "https://api.openai.com/v1/chat/completions",
add_headers(
Authorization = paste("Bearer", api_key),
"Content-Type" = "application/json"
),
body = toJSON(list(
model = "gpt-4o",
messages = list(
list(role = "user", content = prompt)
)
), auto_unbox = TRUE)
)
# Parse and print response
content <- content(response, "parsed")
cat(content$choices[[1]]$message$content)
# Save the table
text <- content$choices[[1]]$message$content
lines <- unlist(strsplit(text, "\n"))
table_lines <- lines[grepl("^\\|", lines)]
# Remove the first two rows
data_lines <- table_lines[-c(1, 2)]
# Convert to a matrix
max_cols <- max(sapply(str_split(data_lines, "\\|"), length))
data_matrix <- str_split_fixed(data_lines, "\\|", max_cols)
# Convert to a dataframe
data_df <- as.data.frame(data_matrix)
# Clean the dataframe
data_df <- data_df[, c(2:4)]
data_df <- data_df %>% mutate(across(everything(), str_trim))
names(data_df) <- c("index", "perception", "labels")
data_df$index <- as.numeric(data_df$index)
# Join the results back to the comments data
comments_ai_2 <- comments %>% left_join(data_df, by = "index")
View(comments_ai_2)
# Convert to a dataframe
data_df <- as.data.frame(data_matrix)
# Clean the dataframe
data_df <- data_df[, c(2:3)] # Modify the columns accordingly
data_df <- data_df %>% mutate(across(everything(), str_trim))
names(data_df) <- c("index", "labels")
data_df$index <- as.numeric(data_df$index)
# Join the results back to the comments data
comments_ai_2 <- comments %>% left_join(data_df, by = "index")
# Save results
write.csv(comments_ai_2, file = "ai_output_2.csv", row.names = F)
ai_output_2 <- read.csv("ai_output_2.csv")
View(ai_output_2)
# Save data needed for presentation
save(sample, sample_name_masked, ai_output, ai_output_2, file = "data.RData")
rnl <- read_excel("/Users/xia2128737/Library/CloudStorage/GoogleDrive-xia2128737@paradisevalley.edu/Shared drives/PV IE Team/Surveys/Ruffalo Noel Levitz Survey 2025/data/data 2025.xlsx")
library(tidyverse)
library(readxl)
library(spacyr)
# Get data
rnl <- read_excel("/Users/xia2128737/Library/CloudStorage/GoogleDrive-xia2128737@paradisevalley.edu/Shared drives/PV IE Team/Surveys/Ruffalo Noel Levitz Survey 2025/data/data 2025.xlsx")
rnl <- rnl %>% filter(!if_all(everything(), is.na))
rnl25 <- rnl %>% filter(SurveyAdministrationName == "Paradise Valley Community College - SSI - 4/2025")
comments <- rnl25 %>% mutate(index = c(1:nrow(rnl25))) %>%
select(index, OpenEndedComments) %>%
filter(!is.na(OpenEndedComments))
View(comments)
rnl <- read_excel("/Users/xia2128737/Library/CloudStorage/GoogleDrive-xia2128737@paradisevalley.edu/Shared drives/PV IE Team/Surveys/Ruffalo Noel Levitz Survey 2025/data/data 2025.xlsx")
library(tidyverse)
library(readxl)
library(spacyr)
# Get data
rnl <- read_excel("/Users/xia2128737/Library/CloudStorage/GoogleDrive-xia2128737@paradisevalley.edu/Shared drives/PV IE Team/Surveys/Ruffalo Noel Levitz Survey 2025/data/data 2025.xlsx")
rnl <- rnl %>% filter(!if_all(everything(), is.na))
rnl25 <- rnl %>% filter(SurveyAdministrationName == "Paradise Valley Community College - SSI - 4/2025")
comments <- rnl25 %>% mutate(index = c(1:nrow(rnl25))) %>%
select(index, OpenEndedComments) %>%
filter(!is.na(OpenEndedComments))
sample <- comments %>%
filter(index %in% c(5, 100, 140, 141, 179, 202)) %>%
slice(c(1, 4, 3, 2, 5)) %>%
mutate(index = c(1:5)) %>%
rename(comment = OpenEndedComments)
View(sample)
rnl <- read_excel("/Users/xia2128737/Library/CloudStorage/GoogleDrive-xia2128737@paradisevalley.edu/Shared drives/PV IE Team/Surveys/Ruffalo Noel Levitz Survey 2025/data/data 2025.xlsx")
rnl <- rnl %>% filter(!if_all(everything(), is.na))
rnl25 <- rnl %>% filter(SurveyAdministrationName == "Paradise Valley Community College - SSI - 4/2025")
comments <- rnl25 %>% mutate(index = c(1:nrow(rnl25))) %>%
select(index, OpenEndedComments) %>%
filter(!is.na(OpenEndedComments))
sample <- comments %>%
filter(index %in% c(5, 100, 140, 141, 179, 202)) %>%
# slice(c(1, 4, 3, 2, 5)) %>%
# mutate(index = c(1:5)) %>%
rename(comment = OpenEndedComments)
sample <- comments %>%
filter(index %in% c(5, 100, 140, 141, 179, 202)) %>%
# slice(c(1, 4, 3, 2, 5)) %>%
# mutate(index = c(1:5)) %>%
rename(comment = OpenEndedComments)
sample <- comments %>%
filter(index %in% c(5, 15, 100, 140, 141)) %>%
# slice(c(1, 4, 3, 2, 5)) %>%
# mutate(index = c(1:5)) %>%
rename(comment = OpenEndedComments)
sample <- comments %>%
filter(index %in% c(5, 15, 140, 141, 179)) %>%
# slice(c(1, 4, 3, 2, 5)) %>%
# mutate(index = c(1:5)) %>%
rename(comment = OpenEndedComments)
rnl <- read_excel("/Users/xia2128737/Library/CloudStorage/GoogleDrive-xia2128737@paradisevalley.edu/Shared drives/PV IE Team/Surveys/Ruffalo Noel Levitz Survey 2025/data/data 2025.xlsx")
rnl <- rnl %>% filter(!if_all(everything(), is.na))
rnl25 <- rnl %>% filter(SurveyAdministrationName == "Paradise Valley Community College - SSI - 4/2025")
comments <- rnl25 %>% mutate(index = c(1:nrow(rnl25))) %>%
select(index, OpenEndedComments) %>%
filter(!is.na(OpenEndedComments))
sample <- comments %>%
filter(index %in% c(5, 15, 140, 141, 179)) %>%
mutate(index = c(1:5)) %>%
rename(comment = OpenEndedComments)
# Function to mask names mentioned in the data
spacy_initialize(model = "en_core_web_lg")
mask_entities <- function(text) {
parsed <- spacy_parse(text, entity = TRUE)
persons <- parsed %>% filter(str_detect(entity, "PERSON")) %>% select(token)
if (nrow(persons) > 0) {
masked <- str_replace_all(text, regex(paste0("\\b(", paste(persons$token, collapse="|"), ")\\b")), "[PERSON]")
} else {
masked <- text
}
return(masked)
}
# Mask names
sample_name_masked <- sample
for (i in 1:nrow(sample_name_masked)) {
sample_name_masked$comments[i] <- mask_entities(sample_name_masked$comments[i])
}
mask_entities <- function(text) {
parsed <- spacy_parse(text, entity = TRUE)
persons <- parsed %>% filter(str_detect(entity, "PERSON")) %>% select(token)
if (nrow(persons) > 0) {
masked <- str_replace_all(text, regex(paste0("\\b(", paste(persons$token, collapse="|"), ")\\b")), "[PERSON]")
} else {
masked <- text
}
return(masked)
}
# Mask names
sample_name_masked <- sample
for (i in 1:nrow(sample_name_masked)) {
sample_name_masked$comment[i] <- mask_entities(sample_name_masked$comment[i])
}
View(sample_name_masked)
# Convert the dataframe to text
comments_text <- paste(capture.output(write.csv(comments, row.names = F)), collapse = "\n")
comments_text
# Convert the dataframe to text
comments_text <- paste(capture.output(write.csv(sample_name_masked, row.names = F)), collapse = "\n")
comments_text
# Prompt 1 ====
prompt <- paste("You are analyzing open-ended comments from a student satisfaction survey.\n\n", comments_text,
"\n\n Task 1: Determine the overall perception of each comment toward the college.
Choose one of the following categories: (a) positive, (b) negative, (c) neutral, or (d) mixed.
Task 2: Identify the topics mentioned in each comment.
Use clear and descriptive labels such as advising, class availability, faculty, etc.
Please create new topic labels as needed.
List all relevant labels, separated by commas, such as ‘advising, class availability’.
Return the results in a table with the following three columns: index, perception, and labels.")
# API call
response <- POST(
url = "https://api.openai.com/v1/chat/completions",
add_headers(
Authorization = paste("Bearer", api_key),
"Content-Type" = "application/json"
),
body = toJSON(list(
model = "gpt-4o",
messages = list(
list(role = "user", content = prompt)
)
), auto_unbox = TRUE)
)
library(httr)
library(jsonlite)
response <- POST(
url = "https://api.openai.com/v1/chat/completions",
add_headers(
Authorization = paste("Bearer", api_key),
"Content-Type" = "application/json"
),
body = toJSON(list(
model = "gpt-4o",
messages = list(
list(role = "user", content = prompt)
)
), auto_unbox = TRUE)
)
# Parse and print response
content <- content(response, "parsed")
cat(content$choices[[1]]$message$content)
# Save the table
text <- content$choices[[1]]$message$content
lines <- unlist(strsplit(text, "\n"))
table_lines <- lines[grepl("^\\|", lines)]
# Remove the first two rows
data_lines <- table_lines[-c(1, 2)]
# Convert to a matrix
max_cols <- max(sapply(str_split(data_lines, "\\|"), length))
data_matrix <- str_split_fixed(data_lines, "\\|", max_cols)
# Convert to a dataframe
data_df <- as.data.frame(data_matrix)
# Clean the dataframe
data_df <- data_df[, c(2:4)] # Modify the columns accordingly
data_df <- data_df %>% mutate(across(everything(), str_trim))
names(data_df) <- c("index", "perception", "labels") # Modify the columns accordingly
data_df$index <- as.numeric(data_df$index)
# Join the results back to the comments data
comments_ai <- comments %>% left_join(data_df, by = "index")
View(comments_ai)
# Join the results back to the comments data
comments_ai <- sample_name_masked %>% left_join(data_df, by = "index")
View(comments_ai)
prompt <- paste("You are analyzing open-ended comments from a student satisfaction survey.\n\n", comments_text,
"\n\n Your task is to code each comment using none, one, or more of the following standardized labels:
Campus Climate – Comments about the general environment or sense of belonging on campus (e.g., feeling cared for, welcomed, respected, or included).
Advising – Comments about academic advising, advisor helpfulness, or access to advisors.
Classes/Schedules – Comments about class offerings, availability, scheduling, or course registration timing.
Faculty/Instruction – Comments about instructors, teaching quality, or classroom experiences.
Facilities – Comments about physical campus resources such as parking lots, gyms, cafeterias, buildings, or classrooms.
Academic Program – Comments about specific academic programs or majors (e.g., Nursing, Music, Education).
Admissions/Registration – Comments about enrollment, admissions, or registration processes.
Other Services – Comments about campus services other than Advising or Admissions/Registration, such as Veterans Services, Counseling, Athletics, Library, Tutoring, Career Services, Disability Services, or Student Clubs.
Instructions: Please do not create new labels. If a comment fits multiple labels, include all relevant ones separated by commas, such as ‘Campus Climate, Academic Program’.
The output should be a table with two columns: index and labels.")
# API call
response <- POST(
url = "https://api.openai.com/v1/chat/completions",
add_headers(
Authorization = paste("Bearer", api_key),
"Content-Type" = "application/json"
),
body = toJSON(list(
model = "gpt-4o",
messages = list(
list(role = "user", content = prompt)
)
), auto_unbox = TRUE)
)
# Parse and print response
content <- content(response, "parsed")
cat(content$choices[[1]]$message$content)
# Save the table
text <- content$choices[[1]]$message$content
lines <- unlist(strsplit(text, "\n"))
table_lines <- lines[grepl("^\\|", lines)]
# Remove the first two rows
data_lines <- table_lines[-c(1, 2)]
# Convert to a matrix
max_cols <- max(sapply(str_split(data_lines, "\\|"), length))
data_matrix <- str_split_fixed(data_lines, "\\|", max_cols)
# Convert to a dataframe
data_df <- as.data.frame(data_matrix)
# Clean the dataframe
data_df <- data_df[, c(2:3)] # Modify the columns accordingly
data_df <- data_df %>% mutate(across(everything(), str_trim))
names(data_df) <- c("index", "labels") # Modify the columns accordingly
data_df$index <- as.numeric(data_df$index)
# Join the results back to the comments data
comments_ai_2 <- sample_name_masked %>% left_join(data_df, by = "index")
View(comments_ai_2)
write.csv(sample, file = "sample data.csv", row.names = F)
save(sample, sample_name_masked, comments_ai, comments_ai_2, file = "data.RData")
library(httr)
library(jsonlite)
library(tidyverse)
library(googledrive)
library(googlesheets4)
drive_auth()
df <- read_sheet("https://docs.google.com/spreadsheets/d/18Mv-oXztQZnYsZ4EHA8ELWV2Yv0azqosW2x5Xf0eVp8/edit?resourcekey=&gid=13002924#gid=13002924")
View(df)
df %>% filter(Timestamp > '2025-11-06')
df %>% filter(Timestamp > '2025-11-08')
df %>% filter(Timestamp = '2025-11-08')
df %>% filter(Timestamp == '2025-11-08')
df %>% filter(Timestamp == '2025-11-07')
df %>% filter(Timestamp == '2025-11-07 21:06:52')
df %>% filter(Timestamp >= '2025-11-07')
df %>% filter(Timestamp > '2025-11-07')
library(httr)
library(jsonlite)
library(tidyverse)
library(googlesheets4)
df <- read_sheet("https://docs.google.com/spreadsheets/d/18Mv-oXztQZnYsZ4EHA8ELWV2Yv0azqosW2x5Xf0eVp8/edit?resourcekey=&gid=13002924#gid=13002924")
# Keep data needed
df <- df[, 3]
View(df)
# Read data
df <- read_sheet("https://docs.google.com/spreadsheets/d/18Mv-oXztQZnYsZ4EHA8ELWV2Yv0azqosW2x5Xf0eVp8/edit?resourcekey=&gid=13002924#gid=13002924")
# Keep data needed
df <- df[c(2:), 3]
# Read data
df <- read_sheet("https://docs.google.com/spreadsheets/d/18Mv-oXztQZnYsZ4EHA8ELWV2Yv0azqosW2x5Xf0eVp8/edit?resourcekey=&gid=13002924#gid=13002924")
# Keep data needed
df <- df[-1, 3]
View(df)
# Keep data needed
df <- df[, 3]
df <- read_sheet("https://docs.google.com/spreadsheets/d/18Mv-oXztQZnYsZ4EHA8ELWV2Yv0azqosW2x5Xf0eVp8/edit?resourcekey=&gid=13002924#gid=13002924")
# Keep data needed
df <- df[, 3]
View(df)
# Keep data needed
df <- df[, c(2,3)]
df <- read_sheet("https://docs.google.com/spreadsheets/d/18Mv-oXztQZnYsZ4EHA8ELWV2Yv0azqosW2x5Xf0eVp8/edit?resourcekey=&gid=13002924#gid=13002924")
# Keep data needed
df <- df[, c(2,3)]
View(df)
